曹操专车
zookeeper的watcher乐观锁怎么实现?
	悲观锁，悲观并发控制（Pessimistic Concurrency Control PCC）,非常严格的并发控制策略。
	强烈的独占和排他特性。有效避免不同事物对同一数据并发更新而造成的数据一致性。只有一把钥匙。
	悲观锁的特点是一定得加锁。=写锁+读锁
	写锁，排他锁
		事务T对 对象O加了写锁。整个期间，只允许T对O进行读取和更新，其他任何事务都不能读。
	共享锁，读锁
		如果事务T对O加了共享锁，T只能对O进行读取，不能更新。其他事务也只能加共享，直到所有得共享锁都释放。
	
	
	乐观锁，乐观并发控制（Optimistic Concurrency Control OCC）。
	再事务处理的大部分时间不需要加锁。再更新请求提交前，每个事务会先检查当前事务读取后，是否有其他事务修改了数据。如果有更新，则回滚。
	【就像提交代码，发现服务器已经更新了，就不能直接提交了】
	三个阶段：数据读取+写入校验【重要，检查数据更新】+数据写入
	zookeeper ，通过version的版本号来控制。【这个也像代码提交】
	version = setDataRequest.getVersion();//这个请求的版本
	int currentVersion=nodeRecord.stat.getVersion();//服务器版本
	if(version!=-1 && version !=currentVersion){//-1不需要乐观锁
		throw new KeeperException.BadVersionException(path);
	}
	version = currentVersion+1;
	
	watch特性总结
	1 一次性，无论是服务端还是客户端，一旦出发，zookeeper就好移除他。因此需要反复注册，有效减轻了服务端得压力
	2watch回调得过程是串行同步，保证了顺序。不能让一个watch影响了整个客户端得回调，需要watch得实现类需要另开一个线程处理业务。
	3轻量 watcherEvent是通知机制的最小通知单元。=状态+事件类型+节点路径。只告诉出事了，不告诉你出了什么事。getState.getType.getPath
	 比如数据更变，无法得到原始数据和新数据。需要client主动重新获取数据。
	 一个简单的不敬业的报信人。
	 
追问：5分钟描述zookeeper？
	雅虎开源的分布式协调服务。可以用zk实现数据发布订阅，负载均衡，命名服务，分布式通知，集群管理，master选举，分布式锁，分布式队列
	几个核心概念：
	集群三个角色，Leader，Follower，Observer。一个集群一个Leader ，操盘手。不深入了，没完了，下面事具体链接
	http://baijiahao.baidu.com/s?id=1594926658760590756&wfr=spider&for=pc
	
一个项目的整体流程？

一个空间换时间的场景：
缓存都是空间换时间，hash的处理基本都是	

centos7的内存分配方式和6有啥不同
不会

你对公司有什么价值？
个人贡献，团队贡献，

美亚柏科
kafka为什么性能这么好？
顺序写入，Mmap内存映射文件，Zero Copy，
顺序写入：硬盘慢在寻址，顺序IO，每个Partition一个文件，收到信息就插入文件末尾。缺点无法删除数据，删除地址就变了。保留所有数据，消费者
对每个topic都有一个offset表示读取到第几条。不删除，硬盘会满。两种删除测了，一个基于时间，一个jiyupartition大小。 cfg配置【producer.properties，consumer.properties，server.properties】
Mmap：现在操作系统的分页存储，Page能 从文件到物理内存的直接映射，20G左右。立刻flush到硬盘事sync，否则事async异步。
ZeroCopy:一个webserver传送一个静态文件，如何优化？zerocopy。
内核的read buffer-【用户程序】-内核-socketbuffer-网卡。中间的用户程序省略了，直接在内核空间操作，就事零复制。
NIO的FileChannle的transferTo和transferFrom都是零复制。
https://mp.weixin.qq.com/s?__biz=MzIxMjAzMDA1MQ==&mid=2648945468&idx=1&sn=b622788361b384e152080b60e5ea69a7#%23

有赞
G1和CMS的区别？G1的缺点
G1事java7的新特征，长远目标事代替CMS收集器。用哪个事JVM配置参数。G1事Garbage First
一个简单的回收过程事： 标记，正常清除，压缩清除。标记哪些没使用，清除没有使用的。把所有的使用的放在一起。
可优化的地方：1大多数新对象可能没用（28定律）2经过多词回收的对象可能以一直存活下来。
于是有了分代回收。

CMS：初始标记，并发标记，重新标记，并发清除
G1：初始标记，并发标记，最终标记，筛选回收

CMS：
1初始标记 stop the world，停止所有线程，Root能直接关联到的所有对象。广度优先遍历。速度很快
2并发标记，回收线程和用户程序并发，GCRootTracing，就是深度遍历。
3重新标记，stoptheworld，处理并发标记时，用户线程产生的增量 数据变动。停顿时间比1长点，远比2时间短。
优点：并发手机，低停顿
缺点：并发阶段，占用线程，总吞吐量降低。 并发阶段，新产生的垃圾【标记使用，之前标记使用的，现在不用了，无法知道】，CMS无法这次处理，只能下次处理。
CMS时标记清除算法那，容易出现大量碎片，多的时候，给大对象分配带来麻烦。不能步提取触发gc。

G1：


G1和CMS的区别：
G1在压缩空间有优势，
G1把内存空间分词Region的方式避免碎片。
Eden和Survivor，Old区不再固定，使用更灵活
G1 设置预期停顿时间，来控制GC时间，避免雪崩
G1在回收后，马上坐合并内存，CMS时在STW-stoptheworld的时候做。
G1会在Yong中使用，而CMS只能在O区使用【年轻代由其他收集齐处理】。

tps，qps

Kafka的整体架构？

Netty一次请求的过程

Http请求时长连接吗？

偏向锁，轻量级锁，自旋锁，重量级锁
java锁基本知识
宏观上=乐观锁+悲观锁
乐观锁，认为读多写少，并发写的可能低，不用上锁。更新请检查版本cas操作。
悲观锁，写多，并发可能高，Synchronized时悲观锁，AQS框架下，先尝试cas乐观锁，获取不到。才会转为悲观锁，RetreenLock

java线程代价
java线程是映射到os原生线程上的。要阻塞或者唤醒一个线程，需要os介入。需要在用户态和核心态间切换。如果切换高频会小号很多cpu时间。
synchronized让得不到锁的进行阻塞状态，是重量级锁。为了性能，java1.5. 引入轻量锁，偏向锁，自旋锁都是乐观锁。

markword
markword是java对象数据结构的一部分，长度64bit。其中最后有2-3位用来标记锁。
01 是未锁定，前面存对象的hashcode和分类年龄
00 轻量锁  指向栈中锁记录的指针
10 指向重量锁的指针
11 GC标记， 要回收了，不记录其他信息
01 偏向锁，偏向线程Id，偏向时间戳，分代年龄。 【101偏向，001无锁】

总结：java 4种锁，重量-自旋-轻量-偏向
没用最好最坏，每种锁都在一定的情况下最合适。

自旋： 有锁的线程在很短时间释放锁资源，等待锁的不需要在内核态和用户态之间切换进去阻塞，需要自己等一等，在门口转一转。自旋。避免消耗。
避免切换，但还是消耗cpu，异能一直这样，有超时时间。
-XX：+UseSpinning 开启

synchronized：把对象当作锁
1 方法，锁住的是对象this
2 静态方法，class实例，class数据在用就去PermGen，全局共享，相当于类的全局锁。锁住所有调用该方法的线程。
3 对象，锁住所有以该对象为锁的代码块。

偏向-轻量-重量，前面的失败才进去后面。

简要说明几个锁。这几个锁不是我们控制的，是代码控制的。思想可以借鉴：
1 减少锁时间，不需要同步执行的代码，尽量不要放在同步块内
2 减少锁力度。讲物理上的一个锁，拆成逻辑上的多个锁。空间换时间。增加并行度。java很多都是这个思想
ConcurrentHashMap,在java8之前，使用Segment数组。
Segment继承了ReenTrantLock，每个Segment就是个可重入锁，然后每个Segment有个
HashEntry，put操作，先确定放入哪个Segment，只锁定这个。这样增加了并发。
LongAdder，内部一个cell数组，具体没看
LinkedBlockingQueue 队列头入队，队尾出队。两边使用不同的锁。
拆锁的粒度不能无限，最多可以将一个锁拆成n个锁。n是cpu的数量。

锁的粗化：
有一个循环，内部要加锁。应该把锁放在循环外，否则每次都要切换。

使用读写锁：
ReentrantReadWriteLock是一个读写锁，读操作加读锁，可以并发读。写操作使用写锁，单线程写。

读写分离：
CopyOnWriteArrayList
怎么分离，写时copy一份，备份写入，原本继续读。当然还有写的等待写锁。
用于读多写少，写完后，引用 指向新的。

使用cas：
线性竞争不激烈，可以用volatiled+cas

消除缓存行的伪共享：

http301和302的区别：


如何设计短链接？
学习知识，不是一定要背下来。建个索引，快速使用。
产生原因：twiiter限制140个字符，发个微博，发个链接，无法写字了。
设计的原则snake
s 设计场景，宏观是需求围观是接口。
n限定条件，比如每秒5000个。日活用户或者qps
a输入输出，宏观是模型，微观是算法
k是数据， hash算法
e 是优化。
基本这五个步骤：
场景1：插入短链接，查找长连接。
写和读【大部分场景都写入抽象成这两个】。
限定：总用户1亿，日活可能100w。算每秒请求量。
插入：低频，每天100w，假设1%，重度用户，1天插入10个。 1年=360w。
1天86400秒。
每秒1.2

读：


算法：
class shoter{
	map longtos
	map stolong
	
	insert
	if 不存在，才创建
		gen（）
	
	gen
	1最简单返回id，风险被黑客利用。
	2 62位编码
	
数据压力：
长链接100bytes，短int 4bytes。一年 10w*108=10.8mb.1一年365*10.8mb=4G

每次random：
	有冲突，重算，2次碰撞更低。

cache
启动时，预存，太多了，LRU。

总结：
日活用户是基础
插入查找算清楚
字母编码省空间
随机
	
}

MD5是i信息摘要算法，将str，文件，执行md5后，生成一个固定长度的128bit的串。4个2二进制bit用一个16进制数字表示。
128bit就变成了32位。如d3379f609e1aa88da2f50018d4fa218f。

ThreadLocal如果引用一个static变量是不是线程安全的？
ThreadLocal是局部变量是安全的。
静态和成员变量是不安全的。
局部变量，存在每个线程自己的方法栈中。

美团：
netty写流程？

redis数据结构的实现？字符串是怎么实现的？有什么优势？
	动态字符串结构sds
	优点：动态扩展内存，二进制安全，和c的字符串类型兼容
	header（len+最大容量+flag）+data
	len是字符串大长度，获取长度的时间是O（1）。
	flag是5中，满足不同长度字符串。len的类型是int8,int16,int32,int64.
	不同需求，不同字符串，节省空间。flag=s[-1],拿到header，必须知道类型，才知道
	取多长，而flag就是设置的。长度不够，会动态扩容。
	
kafka防止订单重复提交？
订单提交是service方法。


阿里ONS【消息系统】的应用场景
异步，解耦，最终一致，并行。
普通青年：编辑微信，群发
文艺，编辑微信，交给秘书发送，自己干别的。
二逼：编辑，发送，编辑，发送。
这个故事告诉大家一个概念：什么是消息系统，这里秘书就是。

例子：淘宝充值100元话费。
交易创建-交易日志-直冲系统-其他200个系统
假设，每个步骤10ms，203个系统，2030ms，一笔交易最少2s。用户体验不太好。很可能被
用户中断。
快的核心让用户等的时间段短。最简单的想法就是并行。
交易创建-【交易日志，直冲系统，其他200个系统】，时间是最慢的那个。20ms
如果一个系统慢了，比如直冲，10s，导致交易成了10s了。这个绝对不行。如果
引入一个小秘书就解决了。
交易创建-消息队列-【交易日志，直冲系统，其他200个系统】。
只要消息队列高效稳定，就绝不影响用户体验。
直冲down机了再上线，消息可以重新发送。 这样就保持了【所有数据状态】最终一致。
消息是并行发送出来，也是并行被执行的。

设计思路和实现方式
任何一个中间件核心 都在于权衡和取舍
消息中间件设计假定：
	每台PC都可能down机不可服务。
	任何集群都可能处理能力不足。100个计算，生产者10个计算，消费者90个计算。
	最坏情况一定会发生。【量太大了，漏洞一定会发生】
	内网环境需要低延迟来提供最佳用户体验。【投递延迟】
设计：
分布式集群化
强数据安全【数据强一致】
海量数据堆积【】
毫秒级投递延迟【】

发布者是集群
消息队列是集群
订阅者是集群
任何一个点都必须能自由扩展，否则一定会成为单点。

1 消息服务器，随机给订阅者，只要消费成功，就是消费成功。【不是广播】
好处：三个集群都可以按需扩缩

2数据安全和高可用：【面向失败，经常失败，必须安全，高可用】
任何一个队列，都是可以用raid保证数据冗余的。绝不丢失
扩及异步复制冗余，队列挂了，队列保存高可用。应用可用性
多组不同消息队列，一组down了，可用另一组。应用可用性

3堆积【面向失败】
任一集群都可能处理能力不足。
11，11 后台300-400应用接消息，前端写入非常快。
10或者100亿的堆积。这时消息中间件down机了，绝不能接受。
或者写入时间几秒，也不能接受。
（1）不能慢（2）不能挂
qps非常高，可能非常激进的使用内存，但是堆积就会崩。

4毫秒级投递延迟
推，拉，推拉结合。
kafka，面向日志分析和统计，关心的是日志拉取的吞吐量。不关心日志拉取的延迟。设计
注意用拉。
这里用推拉结合，
主动推，订阅者接受消息，给我个ack，完成推送。优势，延迟小。因为我有了消息立刻推送。
订阅者很轻量，收消息，处理。
拉消息：15秒拉一次。如果1s一次，对服务器来说压力大。这种情况一般关注吞吐量。
推拉结合：有消息，我推消息通知你来拉。问题是交互次数多。
ons的模型：15秒拉一起，没用消息，hold住，有消息再返回。拉的方式实现及时模式。

关键概念
topic主题：比如书的标题，交易消息，
tag 消息类型，第二级，书的目录，交易创建，交易完成。
发送/订阅组：消息服务很多没用集群的概念。
生产者group，增加机器，标记成组，就生效。【用户加到group】
~8：45


问题：乱序问题如何解决

问题：重复问题如何解决	

案例：利用ONS完成分布式事务，
	
	
	
	
JVM 硬盘读写过高的一次过程。
主要思路是找到 运行的java Thread 卡顿的代码行数
步骤 java进程-占比最高的线程-在jvm的进程日志中 查找线程id 

（1）java进程 ps-aux|grep java
通过任务管理的pid找到 ,假设pid=1234
（2）java线程 top -Hp 
无法直接看，通过Process Explorer.exe, 
找到进程pid=1234，右键属性，看内部占比cpu高的tid（thread id）
（3）threadid进制转换
jvm的thread id是16进制的。
如果 步骤2的tid=9368， 转成十六进制=2498
（4）生成进程日志
d:\opt\quetzaco\quetapp\jre\bin\jstack 1234 > D:\1234.txt
(5)搜索
1234.txt中搜索 0x2498
	
	
	
	
	
	
	